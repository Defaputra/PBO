{"cells":[{"cell_type":"markdown","id":"f89f7684","metadata":{"id":"f89f7684"},"source":["# Hands-On Pertemuan 6: Data Processing dengan Apache Spark"]},{"cell_type":"markdown","id":"e30ce9d1","metadata":{"id":"e30ce9d1"},"source":["## Tujuan:\n","- Memahami dan mempraktikkan data processing menggunakan Apache Spark.\n","- Menggunakan Spark untuk operasi data yang efisien pada dataset besar.\n","- Menerapkan teknik canggih dalam Spark untuk mengatasi kasus penggunaan nyata."]},{"cell_type":"code","source":["pip install pyspark==3.4.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"GQhjEnH9IHXZ","executionInfo":{"status":"ok","timestamp":1727250129808,"user_tz":-420,"elapsed":53685,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"948d1d80-7295-4db4-bf25-bc08c8ab8dae"},"id":"GQhjEnH9IHXZ","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark==3.4.1\n","  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.4.1) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285391 sha256=16e69225d43ee280184d9edd1603797e1bc1d1bcc93a763f332b188990c1315c\n","  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","  Attempting uninstall: pyspark\n","    Found existing installation: pyspark 3.5.3\n","    Uninstalling pyspark-3.5.3:\n","      Successfully uninstalled pyspark-3.5.3\n","Successfully installed pyspark-3.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyspark"]},"id":"ba1b2273a9b749fe9e8f87d62cec739b"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xb7J9KWPESuE","executionInfo":{"status":"ok","timestamp":1727250158383,"user_tz":-420,"elapsed":4308,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"4a4ac735-2c87-426b-c986-f00613a65210"},"id":"xb7J9KWPESuE","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"]}]},{"cell_type":"code","source":["import findspark\n","findspark.init()"],"metadata":{"id":"TINCBou1IpuZ","executionInfo":{"status":"ok","timestamp":1727250214898,"user_tz":-420,"elapsed":386,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}}},"id":"TINCBou1IpuZ","execution_count":4,"outputs":[]},{"cell_type":"code","source":["pip install findspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRYfE7vzIjhc","executionInfo":{"status":"ok","timestamp":1727250226516,"user_tz":-420,"elapsed":3491,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"b3bf2ff2-eb40-441a-c5a5-d6ce231e90f5"},"id":"eRYfE7vzIjhc","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"]}]},{"cell_type":"code","source":["pip install pandas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDp2bQJYIe6R","executionInfo":{"status":"ok","timestamp":1727250177851,"user_tz":-420,"elapsed":3398,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"7b6d5149-9715-44cd-ec34-e001b422852a"},"id":"BDp2bQJYIe6R","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}]},{"cell_type":"markdown","id":"cd5c2f90","metadata":{"id":"cd5c2f90"},"source":["### 1. Pengenalan Spark DataFrames\n","Spark DataFrame menyediakan struktur data yang optimal dengan operasi yang dioptimalkan untuk pemrosesan data besar, yang sangat mirip dengan DataFrame di Pandas atau di RDBMS.\n","\n","- **Tugas 1**: Buat DataFrame sederhana di Spark dan eksplorasi beberapa fungsi dasar yang tersedia."]},{"cell_type":"code","execution_count":9,"id":"986d01c7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"986d01c7","executionInfo":{"status":"ok","timestamp":1727251264127,"user_tz":-420,"elapsed":792,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"da2a5a8a-fbb7-4867-f543-24d7fde5ca3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------+\n","|EmployeeName|Department|Salary|\n","+------------+----------+------+\n","|       James|     Sales|  3000|\n","|     Michael|     Sales|  4600|\n","|      Robert|     Sales|  4100|\n","|       Maria|   Finance|  3000|\n","+------------+----------+------+\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName('HandsOnPertemuan6').getOrCreate()\n","\n","data = [('James', 'Sales', 3000),\n","        ('Michael', 'Sales', 4600),\n","        ('Robert', 'Sales', 4100),\n","        ('Maria', 'Finance', 3000)]\n","columns = ['EmployeeName', 'Department', 'Salary']\n","\n","df = spark.createDataFrame(data, schema=columns)\n","\n","df.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"pvRn5XX8In7i"},"id":"pvRn5XX8In7i","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"fca66b73","metadata":{"id":"fca66b73"},"source":["### 2. Transformasi Dasar dengan DataFrames\n","Pemrosesan data meliputi transformasi seperti filtering, selections, dan aggregations. Spark menyediakan cara efisien untuk melaksanakan operasi ini.\n","\n","- **Tugas 2**: Gunakan operasi filter, select, groupBy untuk mengekstrak informasi dari data, serta lakukan agregasi data untuk mendapatkan insight tentang dataset menggunakan perintah seperti mean, max, sum."]},{"cell_type":"code","execution_count":10,"id":"58232678","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58232678","executionInfo":{"status":"ok","timestamp":1727251358272,"user_tz":-420,"elapsed":6045,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"77d24741-b5f9-4e46-90b7-60d9da03591b"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+------+\n","|EmployeeName|Salary|\n","+------------+------+\n","|       James|  3000|\n","|     Michael|  4600|\n","|      Robert|  4100|\n","|       Maria|  3000|\n","+------------+------+\n","\n","+------------+----------+------+\n","|EmployeeName|Department|Salary|\n","+------------+----------+------+\n","|     Michael|     Sales|  4600|\n","|      Robert|     Sales|  4100|\n","+------------+----------+------+\n","\n","+----------+-----------+\n","|Department|avg(Salary)|\n","+----------+-----------+\n","|     Sales|     3900.0|\n","|   Finance|     3000.0|\n","+----------+-----------+\n","\n","+----------+-----------+\n","|Department|sum(Salary)|\n","+----------+-----------+\n","|     Sales|      11700|\n","|   Finance|       3000|\n","+----------+-----------+\n","\n","+----------+-----------+\n","|Department|max(Salary)|\n","+----------+-----------+\n","|     Sales|       4600|\n","|   Finance|       3000|\n","+----------+-----------+\n","\n"]}],"source":["df.select('EmployeeName', 'Salary').show()\n","\n","df.filter(df['Salary'] > 3000).show()\n","\n","df.groupBy('Department').avg('Salary').show()\n","\n","df.groupBy('Department').sum('Salary').show()\n","\n","df.groupBy('Department').max('Salary').show()"]},{"cell_type":"markdown","id":"89763d36","metadata":{"id":"89763d36"},"source":["### 3. Bekerja dengan Tipe Data Kompleks\n","Spark mendukung tipe data yang kompleks seperti maps, arrays, dan structs yang memungkinkan operasi yang lebih kompleks pada dataset yang kompleks.\n","\n","- **Tugas 3**: Eksplorasi bagaimana mengolah tipe data kompleks dalam Spark DataFrames."]},{"cell_type":"code","execution_count":11,"id":"14701d79","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14701d79","executionInfo":{"status":"ok","timestamp":1727251464749,"user_tz":-420,"elapsed":1172,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"275b47d4-866c-4405-93ab-50036a07e27c"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------+-----------+-----------------+\n","|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n","+------------+----------+------+-----------+-----------------+\n","|       James|     Sales|  3000|      300.0|           3300.0|\n","|     Michael|     Sales|  4600|      460.0|           5060.0|\n","|      Robert|     Sales|  4100|      410.0|           4510.0|\n","|       Maria|   Finance|  3000|      300.0|           3300.0|\n","+------------+----------+------+-----------+-----------------+\n","\n"]}],"source":["df = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n","\n","df = df.withColumn('TotalCompensation', df['Salary'] + df['SalaryBonus'])\n","\n","df.show()"]},{"cell_type":"markdown","id":"5b3b58dd","metadata":{"id":"5b3b58dd"},"source":["### 4. Operasi Data Lanjutan\n","Menggunakan Spark untuk operasi lanjutan seperti window functions, user-defined functions (UDFs), dan mengoptimalkan query.\n","\n","- **Tugas 4**: Implementasikan window function untuk menghitung running totals atau rangkings."]},{"cell_type":"code","execution_count":12,"id":"035312eb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"035312eb","executionInfo":{"status":"ok","timestamp":1727251528535,"user_tz":-420,"elapsed":1743,"user":{"displayName":"Defa A.M.D. Putera","userId":"02260495143105511976"}},"outputId":"d6fe852a-cd64-4dc5-c3e3-dbbad88b4359"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------+-----------+-----------------+----+\n","|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|Rank|\n","+------------+----------+------+-----------+-----------------+----+\n","|       Maria|   Finance|  3000|      300.0|           3300.0|   1|\n","|       James|     Sales|  3000|      300.0|           3300.0|   1|\n","|      Robert|     Sales|  4100|      410.0|           4510.0|   2|\n","|     Michael|     Sales|  4600|      460.0|           5060.0|   3|\n","+------------+----------+------+-----------+-----------------+----+\n","\n"]}],"source":["from pyspark.sql.window import Window\n","from pyspark.sql import functions as F\n","\n","windowSpec = Window.partitionBy('Department').orderBy('Salary')\n","\n","df.withColumn('Rank', F.rank().over(windowSpec)).show()\n"]},{"cell_type":"markdown","id":"f8a097ec","metadata":{"id":"f8a097ec"},"source":["### 5. Kesimpulan dan Eksplorasi Lebih Lanjut\n","Review apa yang telah dipelajari tentang pemrosesan data menggunakan Spark dan eksplorasi teknik lebih lanjut untuk mengoptimalkan pemrosesan data Anda.\n","- **Tugas 5**: Buat ringkasan dari semua operasi yang telah dilakukan dan bagaimana teknik ini dapat diterapkan pada proyek data Anda."]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}